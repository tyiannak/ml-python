{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4af99f",
   "metadata": {},
   "source": [
    "# Feature selection example\n",
    "## Extract audio features \n",
    "Use `pyAudioAnalysis` library to extract audio features for all WAV files in folders `audio\\music` and `audio\\speech`. Use a cache pkl file to store audio features so that they not computed every time this notebook is executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a79ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file 1 of 20: audio/music/m_20451_0.0_1.0.wav\n",
      "Analyzing file 2 of 20: audio/music/m_20620Nutropic20Feat.20Stephane20Belmondo20-20We27ve20Got20It21_0.0_1.0.wav\n",
      "Analyzing file 3 of 20: audio/music/m_21020Teknic20Old20Skool20-20Stop20Trying_0.0_1.0.wav\n",
      "Analyzing file 4 of 20: audio/music/m_21072_0.0_1.0.wav\n",
      "Analyzing file 5 of 20: audio/music/m_21881_0.0_1.0.wav\n",
      "Analyzing file 6 of 20: audio/music/m_22342_0.0_1.0.wav\n",
      "Analyzing file 7 of 20: audio/music/m_22750_0.0_1.0.wav\n",
      "Analyzing file 8 of 20: audio/music/m_23016_0.0_1.0.wav\n",
      "Analyzing file 9 of 20: audio/music/m_23139_0.0_1.0.wav\n",
      "Analyzing file 10 of 20: audio/music/m_23144_0.0_1.0.wav\n",
      "Analyzing file 11 of 20: audio/music/m_23150_0.0_1.0.wav\n",
      "Analyzing file 12 of 20: audio/music/m_23161_0.0_1.0.wav\n",
      "Analyzing file 13 of 20: audio/music/m_23516_0.0_1.0.wav\n",
      "Analyzing file 14 of 20: audio/music/m_23822_0.0_1.0.wav\n",
      "Analyzing file 15 of 20: audio/music/m_23852_0.0_1.0.wav\n",
      "Analyzing file 16 of 20: audio/music/m_24031_0.0_1.0.wav\n",
      "Analyzing file 17 of 20: audio/music/m_8447_0.0_1.0.wav\n",
      "Analyzing file 18 of 20: audio/music/m_9020Goo20Goo20Dolls20-20Slide_0.0_1.0.wav\n",
      "Analyzing file 19 of 20: audio/music/m_9637_0.0_1.0.wav\n",
      "Analyzing file 20 of 20: audio/music/m_9798_0.0_1.0.wav\n",
      "Feature extraction complexity ratio: 40.7 x realtime\n",
      "Analyzing file 1 of 20: audio/speech/s_2495HME654_273.0_274.0.wav\n",
      "Analyzing file 2 of 20: audio/speech/s_271MY7V8IV_11.0_12.0.wav\n",
      "Analyzing file 3 of 20: audio/speech/s_311SY36U31_233.0_234.0.wav\n",
      "Analyzing file 4 of 20: audio/speech/s_34095N1RDU_75.0_76.0.wav\n",
      "Analyzing file 5 of 20: audio/speech/s_342R1YE5O0_99.0_100.0.wav\n",
      "Analyzing file 6 of 20: audio/speech/s_354XIS852R_28.0_29.0.wav\n",
      "Analyzing file 7 of 20: audio/speech/s_371HOEVIMD_110.0_111.0.wav\n",
      "Analyzing file 8 of 20: audio/speech/s_424MNIVJTO_384.0_385.0.wav\n",
      "Analyzing file 9 of 20: audio/speech/s_B0JIQIWD3D_42.0_43.0.wav\n",
      "Analyzing file 10 of 20: audio/speech/s_B4I3XT24MX_68.0_69.0.wav\n",
      "Analyzing file 11 of 20: audio/speech/s_B59MIFHD9L_20.0_21.0.wav\n",
      "Analyzing file 12 of 20: audio/speech/s_B9UOV0Z6VD_57.0_58.0.wav\n",
      "Analyzing file 13 of 20: audio/speech/s_BB0SN7X8ST_61.0_62.0.wav\n",
      "Analyzing file 14 of 20: audio/speech/s_BBE4V8LXRS_30.0_31.0.wav\n",
      "Analyzing file 15 of 20: audio/speech/s_BDLQ3JLHUF_12.0_13.0.wav\n",
      "Analyzing file 16 of 20: audio/speech/s_BDZ6SNTZEO_8.0_9.0.wav\n",
      "Analyzing file 17 of 20: audio/speech/s_BRXOZ15ZBS_30.0_31.0.wav\n",
      "Analyzing file 18 of 20: audio/speech/s_BT4J6J49ED_40.0_41.0.wav\n",
      "Analyzing file 19 of 20: audio/speech/s_BUQH6U01S2_292.0_293.0.wav\n",
      "Analyzing file 20 of 20: audio/speech/s_BVR54TN4ME_11.0_12.0.wav\n",
      "Feature extraction complexity ratio: 29.5 x realtime\n",
      "(40, 138)\n",
      "(40,)\n",
      "(40, 138)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "from pyAudioAnalysis import audioTrainTest as at\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile('data2.pkl'):\n",
    "    with open('data2.pkl','rb') as f:\n",
    "        mid_term_features_2 = pickle.load(f)\n",
    "        wav_file_list2 = pickle.load(f)\n",
    "else:\n",
    "    with open('data2.pkl','wb') as f:\n",
    "        dirs = ['audio/music', 'audio/speech']\n",
    "        # extract features from directories of WAV files:\n",
    "        f1, _, feature_names = mtf.directory_feature_extraction(dirs[0], 1, 1, 0.1, 0.1)\n",
    "        f2, _, feature_names = mtf.directory_feature_extraction(dirs[1], 1, 1, 0.1, 0.1)\n",
    "        mid_term_features = [f1, f2]\n",
    "        # convert list of feature matrices to x, y format:\n",
    "        x, y = at.features_to_matrix(mid_term_features)\n",
    "        print(x.shape)\n",
    "        print(y.shape)\n",
    "        m = x.mean(axis=0)\n",
    "        s = np.std(x, axis = 0)\n",
    "        x_2 = (x - m) / s\n",
    "        pickle.dump(x_2, f)\n",
    "        pickle.dump(wav_file_list2, f)\n",
    "print(x_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63f4b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 138)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15611461",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a85951f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/pyAudioAnalysis/../sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False,  True,  True, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# #Selecting the Best important features according to Logistic Regression using SelectFromModel\n",
    "sfm_selector = SelectFromModel(estimator=LogisticRegression())\n",
    "sfm_selector.fit(x, y)\n",
    "sfm_selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74fc984a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zcr_mean',\n",
       " 'energy_entropy_mean',\n",
       " 'spectral_entropy_mean',\n",
       " 'spectral_rolloff_mean',\n",
       " 'mfcc_1_mean',\n",
       " 'mfcc_2_mean',\n",
       " 'mfcc_3_mean',\n",
       " 'mfcc_4_mean',\n",
       " 'mfcc_5_mean',\n",
       " 'mfcc_6_mean',\n",
       " 'mfcc_8_mean',\n",
       " 'mfcc_10_mean',\n",
       " 'mfcc_11_mean',\n",
       " 'mfcc_12_mean',\n",
       " 'mfcc_13_mean',\n",
       " 'energy_entropy_std',\n",
       " 'mfcc_1_std',\n",
       " 'mfcc_2_std',\n",
       " 'mfcc_3_std',\n",
       " 'mfcc_4_std',\n",
       " 'mfcc_5_std',\n",
       " 'mfcc_6_std',\n",
       " 'delta energy_entropy_std',\n",
       " 'delta mfcc_1_std',\n",
       " 'delta mfcc_2_std',\n",
       " 'delta mfcc_3_std',\n",
       " 'delta mfcc_4_std',\n",
       " 'delta mfcc_6_std',\n",
       " 'delta mfcc_10_std',\n",
       " 'delta mfcc_11_std',\n",
       " 'delta mfcc_13_std',\n",
       " 'ratio']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "list(compress(feature_names, sfm_selector.get_support().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782a53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
