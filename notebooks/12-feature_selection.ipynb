{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4af99f",
   "metadata": {},
   "source": [
    "# Feature selection example\n",
    "## Extract audio features \n",
    "Use `pyAudioAnalysis` library to extract audio features for all WAV files in folders `audio\\music` and `audio\\speech`. Use a cache pkl file to store audio features so that they not computed every time this notebook is executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a79ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file 1 of 20: audio/music/m_20451_0.0_1.0.wav\n",
      "Analyzing file 2 of 20: audio/music/m_20620Nutropic20Feat.20Stephane20Belmondo20-20We27ve20Got20It21_0.0_1.0.wav\n",
      "Analyzing file 3 of 20: audio/music/m_21020Teknic20Old20Skool20-20Stop20Trying_0.0_1.0.wav\n",
      "Analyzing file 4 of 20: audio/music/m_21072_0.0_1.0.wav\n",
      "Analyzing file 5 of 20: audio/music/m_21881_0.0_1.0.wav\n",
      "Analyzing file 6 of 20: audio/music/m_22342_0.0_1.0.wav\n",
      "Analyzing file 7 of 20: audio/music/m_22750_0.0_1.0.wav\n",
      "Analyzing file 8 of 20: audio/music/m_23016_0.0_1.0.wav\n",
      "Analyzing file 9 of 20: audio/music/m_23139_0.0_1.0.wav\n",
      "Analyzing file 10 of 20: audio/music/m_23144_0.0_1.0.wav\n",
      "Analyzing file 11 of 20: audio/music/m_23150_0.0_1.0.wav\n",
      "Analyzing file 12 of 20: audio/music/m_23161_0.0_1.0.wav\n",
      "Analyzing file 13 of 20: audio/music/m_23516_0.0_1.0.wav\n",
      "Analyzing file 14 of 20: audio/music/m_23822_0.0_1.0.wav\n",
      "Analyzing file 15 of 20: audio/music/m_23852_0.0_1.0.wav\n",
      "Analyzing file 16 of 20: audio/music/m_24031_0.0_1.0.wav\n",
      "Analyzing file 17 of 20: audio/music/m_8447_0.0_1.0.wav\n",
      "Analyzing file 18 of 20: audio/music/m_9020Goo20Goo20Dolls20-20Slide_0.0_1.0.wav\n",
      "Analyzing file 19 of 20: audio/music/m_9637_0.0_1.0.wav\n",
      "Analyzing file 20 of 20: audio/music/m_9798_0.0_1.0.wav\n",
      "Feature extraction complexity ratio: 60.2 x realtime\n",
      "Analyzing file 1 of 20: audio/speech/s_2495HME654_273.0_274.0.wav\n",
      "Analyzing file 2 of 20: audio/speech/s_271MY7V8IV_11.0_12.0.wav\n",
      "Analyzing file 3 of 20: audio/speech/s_311SY36U31_233.0_234.0.wav\n",
      "Analyzing file 4 of 20: audio/speech/s_34095N1RDU_75.0_76.0.wav\n",
      "Analyzing file 5 of 20: audio/speech/s_342R1YE5O0_99.0_100.0.wav\n",
      "Analyzing file 6 of 20: audio/speech/s_354XIS852R_28.0_29.0.wav\n",
      "Analyzing file 7 of 20: audio/speech/s_371HOEVIMD_110.0_111.0.wav\n",
      "Analyzing file 8 of 20: audio/speech/s_424MNIVJTO_384.0_385.0.wav\n",
      "Analyzing file 9 of 20: audio/speech/s_B0JIQIWD3D_42.0_43.0.wav\n",
      "Analyzing file 10 of 20: audio/speech/s_B4I3XT24MX_68.0_69.0.wav\n",
      "Analyzing file 11 of 20: audio/speech/s_B59MIFHD9L_20.0_21.0.wav\n",
      "Analyzing file 12 of 20: audio/speech/s_B9UOV0Z6VD_57.0_58.0.wav\n",
      "Analyzing file 13 of 20: audio/speech/s_BB0SN7X8ST_61.0_62.0.wav\n",
      "Analyzing file 14 of 20: audio/speech/s_BBE4V8LXRS_30.0_31.0.wav\n",
      "Analyzing file 15 of 20: audio/speech/s_BDLQ3JLHUF_12.0_13.0.wav\n",
      "Analyzing file 16 of 20: audio/speech/s_BDZ6SNTZEO_8.0_9.0.wav\n",
      "Analyzing file 17 of 20: audio/speech/s_BRXOZ15ZBS_30.0_31.0.wav\n",
      "Analyzing file 18 of 20: audio/speech/s_BT4J6J49ED_40.0_41.0.wav\n",
      "Analyzing file 19 of 20: audio/speech/s_BUQH6U01S2_292.0_293.0.wav\n",
      "Analyzing file 20 of 20: audio/speech/s_BVR54TN4ME_11.0_12.0.wav\n",
      "Feature extraction complexity ratio: 62.7 x realtime\n",
      "(40, 138)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "from pyAudioAnalysis import audioTrainTest as at\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "if os.path.isfile('data2.pkl'):\n",
    "    # if features already calcualted --> load\n",
    "    with open('data2.pkl','rb') as f:\n",
    "        X = pickle.load(f)\n",
    "        y = pickle.load(f)\n",
    "        feature_names = pickle.load(f)\n",
    "else:\n",
    "    with open('data2.pkl','wb') as f:\n",
    "        # if features not already calculated: extract features from scratch\n",
    "        dirs = ['audio/music', 'audio/speech']\n",
    "        # extract features from directories of WAV files:\n",
    "        f1, _, feature_names = mtf.directory_feature_extraction(dirs[0], 1, 1, 0.1, 0.1)\n",
    "        f2, _, feature_names = mtf.directory_feature_extraction(dirs[1], 1, 1, 0.1, 0.1)\n",
    "        mid_term_features = [f1, f2]\n",
    "        # convert list of feature matrices to x, y format:\n",
    "        x, y = at.features_to_matrix(mid_term_features)\n",
    "        m = x.mean(axis=0)\n",
    "        s = np.std(x, axis = 0)\n",
    "        X = (x - m) / s\n",
    "        pickle.dump(X, f)\n",
    "        pickle.dump(y, f)\n",
    "        pickle.dump(feature_names, f)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15611461",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85951f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zcr_mean', 'energy_mean', 'energy_entropy_mean', 'spectral_centroid_mean', 'spectral_entropy_mean', 'spectral_rolloff_mean', 'mfcc_1_mean', 'mfcc_2_mean', 'mfcc_3_mean', 'mfcc_4_mean', 'mfcc_5_mean', 'mfcc_6_mean', 'mfcc_8_mean', 'mfcc_10_mean', 'mfcc_12_mean', 'chroma_1_mean', 'chroma_3_mean', 'chroma_6_mean', 'chroma_7_mean', 'chroma_10_mean', 'chroma_11_mean', 'chroma_std_mean', 'delta mfcc_6_mean', 'delta mfcc_9_mean', 'delta chroma_11_mean', 'zcr_std', 'energy_std', 'energy_entropy_std', 'spectral_centroid_std', 'spectral_spread_std', 'spectral_entropy_std', 'spectral_rolloff_std', 'mfcc_1_std', 'mfcc_2_std', 'mfcc_3_std', 'mfcc_4_std', 'mfcc_5_std', 'mfcc_6_std', 'mfcc_7_std', 'mfcc_10_std', 'chroma_3_std', 'chroma_5_std', 'chroma_6_std', 'chroma_7_std', 'delta zcr_std', 'delta energy_std', 'delta energy_entropy_std', 'delta spectral_centroid_std', 'delta spectral_entropy_std', 'delta spectral_rolloff_std', 'delta mfcc_1_std', 'delta mfcc_3_std', 'delta mfcc_4_std', 'delta mfcc_6_std', 'delta mfcc_10_std', 'delta mfcc_11_std', 'delta chroma_5_std', 'delta chroma_6_std', 'delta chroma_7_std', 'bpm']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import compress\n",
    "sfm_selector = SelectFromModel(estimator=LogisticRegression())\n",
    "sfm_selector.fit(X, y)\n",
    "list_of_selected_features = list(compress(feature_names, sfm_selector.get_support().tolist()))\n",
    "print(list_of_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fc984a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vk/xf8fjz3n1r55t8g8gqz02fym0000gn/T/ipykernel_6823/3622269051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# get importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mimp_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "print(importance[2])\n",
    "imp_features = [f for i_f, f in enumerate(feature_names) if abs(importance[i_f]) > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782a53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
