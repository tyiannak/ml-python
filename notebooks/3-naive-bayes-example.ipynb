{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data:\n",
    "data_file = \"training.1600000.processed.noemoticon.csv\"\n",
    "from csv import reader\n",
    "count, pos, neg = 0, [], []\n",
    "\n",
    "words_to_use = [\"love\", \"hate\", \"aww\", \"bad\", \"good\", \"great\", \"fuck\", \"jesus\", \"sucks\", \"suck\", \"pleased\", \n",
    "                \"fanntastic\", \"amazing\", \"enjoy\", \"excellent\", \"day\", \"today\", \"yesterday\", \"dad\", \"mom\",\n",
    "                \"kid\", \"child\", \"year\", \"think\", \"way\", \"first\", \"well\", \"even\", \"new\", \"any\", \"most\", \"man\", \"boy\",\n",
    "                \"woman\", \"girl\", \"time\", \"person\", \"sad\", \"happy\", \"yes\", \"no\", \"well\", \"yea\", \"yeah\", \"hell\", \"sure\",\n",
    "                \"ok\", \"wife\", \"husband\", \"kill\", \"ill\", \"sick\", \"illness\", \"sickness\", \"death\", \"virus\", \"dead\", \"killed\", \n",
    "                \"accident\"]\n",
    "\n",
    "with open(data_file, 'r', encoding='mac_roman') as read_obj:\n",
    "    csv_reader = reader(read_obj)\n",
    "    for row in csv_reader:\n",
    "        st = ([s.strip().lower() for s in row])\n",
    "        cur_str = []\n",
    "        # keep only texts that contain the above polarized words \n",
    "        # this makes the task ultra-simple but this is just for demo purposes :-) \n",
    "        found = False\n",
    "        for w in st[-1].split(' '):\n",
    "            if len(w) > 0:\n",
    "                if w in words_to_use:\n",
    "                    found = True\n",
    "                    if w[0] not in ['@']:\n",
    "                        cur_str.append(w.replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\"))\n",
    "        if found:\n",
    "            if (st[0]) == '0':\n",
    "                neg.append(\" \".join(cur_str))\n",
    "            if (st[0]) == '4':\n",
    "                pos.append(\" \".join(cur_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract term frequencies\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words={'english'})\n",
    "# X contains n_documents rows and n_terms columns\n",
    "X = vectorizer.fit_transform(neg + pos).toarray()\n",
    "# list of terms\n",
    "train_words = (vectorizer.get_feature_names())\n",
    "# prior probabilities:\n",
    "prior_1 = len(neg) / (len(pos) + len(neg))\n",
    "prior_2 = len(pos) / (len(pos) + len(neg))\n",
    "# get average frequencies per class --> this is actually the p(x_term | y) for each term and class\n",
    "x1 = vectorizer.transform(neg)\n",
    "p_x_y1 = x1.mean(axis=0).flatten()\n",
    "x2 = vectorizer.transform(pos)\n",
    "p_x_y2 = x2.mean(axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neutral words\n",
      "any \t p(any|y=negative)=0.02903 \t p(any|y=positive)=0.01970\n",
      "boy \t p(boy|y=negative)=0.00537 \t p(boy|y=positive)=0.00531\n",
      "child \t p(child|y=negative)=0.00129 \t p(child|y=positive)=0.00091\n",
      "day \t p(day|y=negative)=0.09433 \t p(day|y=positive)=0.10498\n",
      "first \t p(first|y=negative)=0.02129 \t p(first|y=positive)=0.02914\n",
      "girl \t p(girl|y=negative)=0.01017 \t p(girl|y=positive)=0.01224\n",
      "husband \t p(husband|y=negative)=0.00204 \t p(husband|y=positive)=0.00185\n",
      "ill \t p(ill|y=negative)=0.01121 \t p(ill|y=positive)=0.00843\n",
      "kid \t p(kid|y=negative)=0.00263 \t p(kid|y=positive)=0.00257\n",
      "man \t p(man|y=negative)=0.01480 \t p(man|y=positive)=0.01112\n",
      "mom \t p(mom|y=negative)=0.01220 \t p(mom|y=positive)=0.00934\n",
      "most \t p(most|y=negative)=0.01112 \t p(most|y=positive)=0.01368\n",
      "ok \t p(ok|y=negative)=0.01333 \t p(ok|y=positive)=0.01620\n",
      "person \t p(person|y=negative)=0.00553 \t p(person|y=positive)=0.00548\n",
      "think \t p(think|y=negative)=0.06895 \t p(think|y=positive)=0.05996\n",
      "time \t p(time|y=negative)=0.06939 \t p(time|y=positive)=0.07510\n",
      "today \t p(today|y=negative)=0.07010 \t p(today|y=positive)=0.05088\n",
      "way \t p(way|y=negative)=0.03303 \t p(way|y=positive)=0.03332\n",
      "well \t p(well|y=negative)=0.04096 \t p(well|y=positive)=0.04854\n",
      "wife \t p(wife|y=negative)=0.00216 \t p(wife|y=positive)=0.00257\n",
      "woman \t p(woman|y=negative)=0.00145 \t p(woman|y=positive)=0.00180\n",
      "yea \t p(yea|y=negative)=0.00417 \t p(yea|y=positive)=0.00430\n",
      "yeah \t p(yeah|y=negative)=0.01739 \t p(yeah|y=positive)=0.02105\n",
      "year \t p(year|y=negative)=0.01430 \t p(year|y=positive)=0.00976\n",
      "yesterday \t p(yesterday|y=negative)=0.01050 \t p(yesterday|y=positive)=0.00749\n",
      "\n",
      "Negative words\n",
      "accident \t p(accident|y=negative)=0.00162 \t p(accident|y=positive)=0.00023\n",
      "aww \t p(aww|y=negative)=0.01232 \t p(aww|y=positive)=0.00687\n",
      "bad \t p(bad|y=negative)=0.05938 \t p(bad|y=positive)=0.01358\n",
      "dad \t p(dad|y=negative)=0.00943 \t p(dad|y=positive)=0.00543\n",
      "dead \t p(dead|y=negative)=0.00717 \t p(dead|y=positive)=0.00214\n",
      "death \t p(death|y=negative)=0.00303 \t p(death|y=positive)=0.00115\n",
      "even \t p(even|y=negative)=0.03983 \t p(even|y=positive)=0.02147\n",
      "fuck \t p(fuck|y=negative)=0.00867 \t p(fuck|y=positive)=0.00400\n",
      "hate \t p(hate|y=negative)=0.05585 \t p(hate|y=positive)=0.00816\n",
      "hell \t p(hell|y=negative)=0.00818 \t p(hell|y=positive)=0.00513\n",
      "illness \t p(illness|y=negative)=0.00029 \t p(illness|y=positive)=0.00008\n",
      "kill \t p(kill|y=negative)=0.00465 \t p(kill|y=positive)=0.00222\n",
      "killed \t p(killed|y=negative)=0.00329 \t p(killed|y=positive)=0.00086\n",
      "no \t p(no|y=negative)=0.15371 \t p(no|y=positive)=0.06084\n",
      "sad \t p(sad|y=negative)=0.06851 \t p(sad|y=positive)=0.00344\n",
      "sick \t p(sick|y=negative)=0.03481 \t p(sick|y=positive)=0.00311\n",
      "sickness \t p(sickness|y=negative)=0.00068 \t p(sickness|y=positive)=0.00010\n",
      "suck \t p(suck|y=negative)=0.00588 \t p(suck|y=positive)=0.00161\n",
      "sucks \t p(sucks|y=negative)=0.01935 \t p(sucks|y=positive)=0.00158\n",
      "virus \t p(virus|y=negative)=0.00090 \t p(virus|y=positive)=0.00025\n",
      "\n",
      "Positive words\n",
      "amazing \t p(amazing|y=negative)=0.00547 \t p(amazing|y=positive)=0.01947\n",
      "enjoy \t p(enjoy|y=negative)=0.00501 \t p(enjoy|y=positive)=0.01698\n",
      "excellent \t p(excellent|y=negative)=0.00046 \t p(excellent|y=positive)=0.00218\n",
      "good \t p(good|y=negative)=0.07872 \t p(good|y=positive)=0.17723\n",
      "great \t p(great|y=negative)=0.02034 \t p(great|y=positive)=0.06971\n",
      "happy \t p(happy|y=negative)=0.01800 \t p(happy|y=positive)=0.05996\n",
      "jesus \t p(jesus|y=negative)=0.00067 \t p(jesus|y=positive)=0.00112\n",
      "love \t p(love|y=negative)=0.05153 \t p(love|y=positive)=0.14742\n",
      "new \t p(new|y=negative)=0.05000 \t p(new|y=positive)=0.08669\n",
      "pleased \t p(pleased|y=negative)=0.00039 \t p(pleased|y=positive)=0.00120\n",
      "sure \t p(sure|y=negative)=0.01624 \t p(sure|y=positive)=0.02591\n",
      "yes \t p(yes|y=negative)=0.00953 \t p(yes|y=positive)=0.01984\n"
     ]
    }
   ],
   "source": [
    "# print terms that are \"almost\" neutral, i.e. p(x_term | y = 0) / p(x_term | y = 1) is close to 1\n",
    "thres = 1.5\n",
    "print(\"\\nNeutral words\")\n",
    "for iw, w in enumerate(train_words):\n",
    "    if p_x_y1[0, iw] / p_x_y2[0, iw] < thres and p_x_y2[0, iw] / p_x_y1[0, iw] < thres:\n",
    "        print(f'{w} \\t p({w}|y=negative)={p_x_y1[0, iw]:.5f} \\t p({w}|y=positive)={p_x_y2[0, iw]:.5f}')\n",
    "print(\"\\nNegative words\")\n",
    "for iw, w in enumerate(train_words):\n",
    "    if p_x_y1[0, iw] / p_x_y2[0, iw] > thres:\n",
    "        print(f'{w} \\t p({w}|y=negative)={p_x_y1[0, iw]:.5f} \\t p({w}|y=positive)={p_x_y2[0, iw]:.5f}')\n",
    "print(\"\\nPositive words\")\n",
    "for iw, w in enumerate(train_words):\n",
    "    if p_x_y2[0, iw] / p_x_y1[0, iw] > thres:\n",
    "        print(f'{w} \\t p({w}|y=negative)={p_x_y1[0, iw]:.5f} \\t p({w}|y=positive)={p_x_y2[0, iw]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(st, f_class1, f_class2, vocabulary, prior1, prior2):\n",
    "    words = st.split(' ')\n",
    "    prob1, prob2 = prior1, prior2\n",
    "    for w in words:\n",
    "        w2 = w\n",
    "        w2 = w2.replace(\"!\", \"\").replace(\"?\", \"\").replace(\".\", \"\").replace(\",\", \"\")\n",
    "        if w2 in train_words:\n",
    "            prob1 *= f_class1[0, vocabulary.index(w2)]\n",
    "            prob2 *= f_class2[0, vocabulary.index(w2)]\n",
    "    probs = np.array([prob1, prob2])\n",
    "    probs /= probs.sum()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5488460676674849\n"
     ]
    }
   ],
   "source": [
    "p = classify(\"ok\", p_x_y1, p_x_y2, train_words, prior_1, prior_2)\n",
    "print(np.argmax(p), p[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9886301550999419\n"
     ]
    }
   ],
   "source": [
    "p = classify(\"i am so sad this is bad news\", p_x_y1, p_x_y2, train_words, prior_1, prior_2)\n",
    "print(np.argmax(p), p[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9804085295673374\n"
     ]
    }
   ],
   "source": [
    "p = classify(\"this is fucking great. this is the most amazing news i've heard in a while, i am so happy\", p_x_y1, p_x_y2, train_words, prior_1, prior_2)\n",
    "print(np.argmax(p), p[np.argmax(p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5003309143494389\n"
     ]
    }
   ],
   "source": [
    "p = classify(\"daskhj adsjkh \", p_x_y1, p_x_y2, train_words, prior_1, prior_2)\n",
    "print(np.argmax(p), p[np.argmax(p)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
